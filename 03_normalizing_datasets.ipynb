{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9933d7fd-2f00-46e7-97e4-521f3280ee62",
   "metadata": {},
   "source": [
    "# Citibike Project - Normalizing the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9786d426-8c89-4b51-88e4-a2715742fc6d",
   "metadata": {},
   "source": [
    "Normalizing the bike share datsets from `03_normalizing_datasets.ipynb` to prepare for SQL database creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aeb382-a82a-47d1-b98d-44c5d9d0d7e0",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42028afd-5ca5-4fc5-b8a9-ffad33886e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import feather\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0712a62f-644a-472c-9321-6280f5c84c03",
   "metadata": {},
   "source": [
    "## Files that we'll be working on: \n",
    "Two .CSVs, `group1` is ~10Gb and `group2` is ~20Gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91eef3b0-cba0-4f0d-973f-89e9cff3d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_location='/Users/sra/files/projects/citibike_project/combined/group1_combined/group1.csv'\n",
    "group2_location='/Users/sra/files/projects/citibike_project/combined/group2_combined/group2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5f3c4-2fa9-4d74-b7ac-5bd611b4fb5e",
   "metadata": {},
   "source": [
    "### Let's explore group1 first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1631a56-2a60-49aa-a1de-589a0ce31d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q=(\n",
    "    pl.scan_csv(group1_location,ignore_errors=True,try_parse_dates=True)\n",
    ")\n",
    "\n",
    "group1_pl=q.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6286754f-1941-4288-8a3f-9f11a6fdcfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ride_id</th><th>rideable_type</th><th>started_at</th><th>ended_at</th><th>start_station_name</th><th>start_station_id</th><th>end_station_name</th><th>end_station_id</th><th>start_lat</th><th>start_lng</th><th>end_lat</th><th>end_lng</th><th>member_casual</th></tr><tr><td>str</td><td>str</td><td>datetime[μs]</td><td>datetime[μs]</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;26A3DC47FE0EA3…</td><td>&quot;docked_bike&quot;</td><td>2021-05-13 12:48:08</td><td>2021-05-13 13:07:37</td><td>&quot;Broadway &amp; W 2…</td><td>6173.08</td><td>&quot;E 2 St &amp; Avenu…</td><td>5515.02</td><td>40.742868</td><td>-73.989186</td><td>40.722174</td><td>-73.983688</td><td>&quot;member&quot;</td></tr><tr><td>&quot;A99F2E1D627B08…</td><td>&quot;docked_bike&quot;</td><td>2021-05-16 08:30:13</td><td>2021-05-16 08:45:47</td><td>&quot;46 Ave &amp; 5 St&quot;</td><td>6286.02</td><td>&quot;34th Ave &amp; Ver…</td><td>6873.01</td><td>40.74731</td><td>-73.95451</td><td>40.765354</td><td>-73.939863</td><td>&quot;member&quot;</td></tr><tr><td>&quot;43E79A45997B73…</td><td>&quot;docked_bike&quot;</td><td>2021-05-01 08:38:14</td><td>2021-05-01 08:54:27</td><td>&quot;46 Ave &amp; 5 St&quot;</td><td>6286.02</td><td>&quot;34th Ave &amp; Ver…</td><td>6873.01</td><td>40.74731</td><td>-73.95451</td><td>40.765354</td><td>-73.939863</td><td>&quot;member&quot;</td></tr><tr><td>&quot;8B3CC649F4F588…</td><td>&quot;docked_bike&quot;</td><td>2021-05-09 08:12:31</td><td>2021-05-09 08:27:05</td><td>&quot;46 Ave &amp; 5 St&quot;</td><td>6286.02</td><td>&quot;34th Ave &amp; Ver…</td><td>6873.01</td><td>40.74731</td><td>-73.95451</td><td>40.765354</td><td>-73.939863</td><td>&quot;member&quot;</td></tr><tr><td>&quot;7101C98F057486…</td><td>&quot;docked_bike&quot;</td><td>2021-05-27 07:52:27</td><td>2021-05-27 08:09:01</td><td>&quot;E 123 St &amp; Lex…</td><td>7636.05</td><td>&quot;1 Ave &amp; E 78 S…</td><td>7020.09</td><td>40.802926</td><td>-73.9379</td><td>40.771404</td><td>-73.953517</td><td>&quot;member&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌───────────┬────────────┬──────────┬───────────┬───┬─────────┬───────────┬───────────┬────────────┐\n",
       "│ ride_id   ┆ rideable_t ┆ started_ ┆ ended_at  ┆ … ┆ start_l ┆ end_lat   ┆ end_lng   ┆ member_cas │\n",
       "│ ---       ┆ ype        ┆ at       ┆ ---       ┆   ┆ ng      ┆ ---       ┆ ---       ┆ ual        │\n",
       "│ str       ┆ ---        ┆ ---      ┆ datetime[ ┆   ┆ ---     ┆ f64       ┆ f64       ┆ ---        │\n",
       "│           ┆ str        ┆ datetime ┆ μs]       ┆   ┆ f64     ┆           ┆           ┆ str        │\n",
       "│           ┆            ┆ [μs]     ┆           ┆   ┆         ┆           ┆           ┆            │\n",
       "╞═══════════╪════════════╪══════════╪═══════════╪═══╪═════════╪═══════════╪═══════════╪════════════╡\n",
       "│ 26A3DC47F ┆ docked_bik ┆ 2021-05- ┆ 2021-05-1 ┆ … ┆ -73.989 ┆ 40.722174 ┆ -73.98368 ┆ member     │\n",
       "│ E0EA3A3   ┆ e          ┆ 13       ┆ 3         ┆   ┆ 186     ┆           ┆ 8         ┆            │\n",
       "│           ┆            ┆ 12:48:08 ┆ 13:07:37  ┆   ┆         ┆           ┆           ┆            │\n",
       "│ A99F2E1D6 ┆ docked_bik ┆ 2021-05- ┆ 2021-05-1 ┆ … ┆ -73.954 ┆ 40.765354 ┆ -73.93986 ┆ member     │\n",
       "│ 27B088F   ┆ e          ┆ 16       ┆ 6         ┆   ┆ 51      ┆           ┆ 3         ┆            │\n",
       "│           ┆            ┆ 08:30:13 ┆ 08:45:47  ┆   ┆         ┆           ┆           ┆            │\n",
       "│ 43E79A459 ┆ docked_bik ┆ 2021-05- ┆ 2021-05-0 ┆ … ┆ -73.954 ┆ 40.765354 ┆ -73.93986 ┆ member     │\n",
       "│ 97B7390   ┆ e          ┆ 01       ┆ 1         ┆   ┆ 51      ┆           ┆ 3         ┆            │\n",
       "│           ┆            ┆ 08:38:14 ┆ 08:54:27  ┆   ┆         ┆           ┆           ┆            │\n",
       "│ 8B3CC649F ┆ docked_bik ┆ 2021-05- ┆ 2021-05-0 ┆ … ┆ -73.954 ┆ 40.765354 ┆ -73.93986 ┆ member     │\n",
       "│ 4F58816   ┆ e          ┆ 09       ┆ 9         ┆   ┆ 51      ┆           ┆ 3         ┆            │\n",
       "│           ┆            ┆ 08:12:31 ┆ 08:27:05  ┆   ┆         ┆           ┆           ┆            │\n",
       "│ 7101C98F0 ┆ docked_bik ┆ 2021-05- ┆ 2021-05-2 ┆ … ┆ -73.937 ┆ 40.771404 ┆ -73.95351 ┆ member     │\n",
       "│ 57486F4   ┆ e          ┆ 27       ┆ 7         ┆   ┆ 9       ┆           ┆ 7         ┆            │\n",
       "│           ┆            ┆ 07:52:27 ┆ 08:09:01  ┆   ┆         ┆           ┆           ┆            │\n",
       "└───────────┴────────────┴──────────┴───────────┴───┴─────────┴───────────┴───────────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1_pl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "483f96a6-4a3f-4277-b454-e2d06e11380c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>start_station_name</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;W 21 St &amp; 6 Av…</td><td>247908</td></tr><tr><td>&quot;West St &amp; Cham…</td><td>219580</td></tr><tr><td>&quot;1 Ave &amp; E 68 S…</td><td>208483</td></tr><tr><td>&quot;6 Ave &amp; W 33 S…</td><td>197135</td></tr><tr><td>&quot;Broadway &amp; W 2…</td><td>194687</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────────────────────┬────────┐\n",
       "│ start_station_name    ┆ count  │\n",
       "│ ---                   ┆ ---    │\n",
       "│ str                   ┆ u32    │\n",
       "╞═══════════════════════╪════════╡\n",
       "│ W 21 St & 6 Ave       ┆ 247908 │\n",
       "│ West St & Chambers St ┆ 219580 │\n",
       "│ 1 Ave & E 68 St       ┆ 208483 │\n",
       "│ 6 Ave & W 33 St       ┆ 197135 │\n",
       "│ Broadway & W 25 St    ┆ 194687 │\n",
       "└───────────────────────┴────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1_pl.groupby('start_station_name').count()\\\n",
    ".sort('count',descending=True)\\\n",
    ".head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc398ce9-89a6-4eea-9503-9f41edd36ef0",
   "metadata": {},
   "source": [
    "There are some junk stations in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b076e86e-a7d6-4dc3-a12b-37de1f3c1e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2_027, 2)\n",
      "┌──────────────────────────┬────────┐\n",
      "│ start_station_name       ┆ count  │\n",
      "│ ---                      ┆ ---    │\n",
      "│ str                      ┆ u32    │\n",
      "╞══════════════════════════╪════════╡\n",
      "│ W 21 St & 6 Ave          ┆ 247908 │\n",
      "│ West St & Chambers St    ┆ 219580 │\n",
      "│ 1 Ave & E 68 St          ┆ 208483 │\n",
      "│ 6 Ave & W 33 St          ┆ 197135 │\n",
      "│ …                        ┆ …      │\n",
      "│ Prototype Lab            ┆ 15     │\n",
      "│ Apache                   ┆ 15     │\n",
      "│ Rogers Pl & E 165 St_old ┆ 11     │\n",
      "│ 4455.10                  ┆ 11     │\n",
      "└──────────────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "q=(\n",
    "    group1_pl.lazy()\n",
    "    .groupby('start_station_name')\n",
    "    .agg(pl.count('start_station_name').alias('count'))\n",
    "    .filter(\n",
    "        (pl.col('count')>=10)\n",
    "    )\n",
    "    .sort('count',descending=True)\n",
    "    # .limit(5)\n",
    ")\n",
    "\n",
    "group1_pl_count=q.collect()\n",
    "print(group1_pl_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb031692-7a8a-490a-aad3-a30955f6593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_927, 2)\n",
      "┌──────────────────┬────────┐\n",
      "│ start_station_id ┆ count  │\n",
      "│ ---              ┆ ---    │\n",
      "│ f64              ┆ u32    │\n",
      "╞══════════════════╪════════╡\n",
      "│ 6140.05          ┆ 247908 │\n",
      "│ 5329.03          ┆ 219580 │\n",
      "│ 6822.09          ┆ 208483 │\n",
      "│ 6364.07          ┆ 197135 │\n",
      "│ …                ┆ …      │\n",
      "│ 5548.01          ┆ 44     │\n",
      "│ 3704.01          ┆ 33     │\n",
      "│ 4014.01          ┆ 30     │\n",
      "│ 8419.03          ┆ 2      │\n",
      "└──────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "q=(\n",
    "    group1_pl.lazy()\n",
    "    .groupby('start_station_id')\n",
    "    .agg(pl.count('start_station_id').alias('count'))\n",
    "    # .filter(\n",
    "        # (pl.col('count')>=1)\n",
    "    # )\n",
    "    .sort('count',descending=True)\n",
    "    # .limit(5)\n",
    ")\n",
    "\n",
    "group1_pl_count=q.collect()\n",
    "print(group1_pl_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0bb8a-a798-4b0e-9251-2216855710bf",
   "metadata": {},
   "source": [
    "## Normalize group1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ab06c-f665-4061-86ff-69917004b3b3",
   "metadata": {},
   "source": [
    "Ride table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9dd51911-05bf-41cd-9906-2681764c7af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (55_800_085, 7)\n",
      "┌──────────────┬────────────┬──────────────┬──────────────┬────────────┬────────────┬──────────────┐\n",
      "│ ride_id      ┆ rideable_t ┆ started_at   ┆ ended_at     ┆ start_stat ┆ end_statio ┆ member_casua │\n",
      "│ ---          ┆ ype        ┆ ---          ┆ ---          ┆ ion_id     ┆ n_id       ┆ l            │\n",
      "│ str          ┆ ---        ┆ datetime[μs] ┆ datetime[μs] ┆ ---        ┆ ---        ┆ ---          │\n",
      "│              ┆ str        ┆              ┆              ┆ f64        ┆ f64        ┆ str          │\n",
      "╞══════════════╪════════════╪══════════════╪══════════════╪════════════╪════════════╪══════════════╡\n",
      "│ 26A3DC47FE0E ┆ docked_bik ┆ 2021-05-13   ┆ 2021-05-13   ┆ 6173.08    ┆ 5515.02    ┆ member       │\n",
      "│ A3A3         ┆ e          ┆ 12:48:08     ┆ 13:07:37     ┆            ┆            ┆              │\n",
      "│ A99F2E1D627B ┆ docked_bik ┆ 2021-05-16   ┆ 2021-05-16   ┆ 6286.02    ┆ 6873.01    ┆ member       │\n",
      "│ 088F         ┆ e          ┆ 08:30:13     ┆ 08:45:47     ┆            ┆            ┆              │\n",
      "│ 43E79A45997B ┆ docked_bik ┆ 2021-05-01   ┆ 2021-05-01   ┆ 6286.02    ┆ 6873.01    ┆ member       │\n",
      "│ 7390         ┆ e          ┆ 08:38:14     ┆ 08:54:27     ┆            ┆            ┆              │\n",
      "│ 8B3CC649F4F5 ┆ docked_bik ┆ 2021-05-09   ┆ 2021-05-09   ┆ 6286.02    ┆ 6873.01    ┆ member       │\n",
      "│ 8816         ┆ e          ┆ 08:12:31     ┆ 08:27:05     ┆            ┆            ┆              │\n",
      "│ …            ┆ …          ┆ …            ┆ …            ┆ …          ┆ …          ┆ …            │\n",
      "│ 3A14299B4F7F ┆ docked_bik ┆ 2021-02-17   ┆ 2021-02-17   ┆ 6584.12    ┆ 6584.12    ┆ member       │\n",
      "│ A1CF         ┆ e          ┆ 18:03:24     ┆ 18:06:39     ┆            ┆            ┆              │\n",
      "│ 7B86EE3DC7E0 ┆ docked_bik ┆ 2021-02-28   ┆ 2021-02-28   ┆ 4721.01    ┆ 4721.01    ┆ casual       │\n",
      "│ 26BC         ┆ e          ┆ 18:58:31     ┆ 19:12:51     ┆            ┆            ┆              │\n",
      "│ D665B8623FC0 ┆ docked_bik ┆ 2021-02-25   ┆ 2021-02-25   ┆ 4066.15    ┆ 4721.01    ┆ casual       │\n",
      "│ 1285         ┆ e          ┆ 09:00:41     ┆ 09:13:56     ┆            ┆            ┆              │\n",
      "│ 08A07BB378B0 ┆ docked_bik ┆ 2021-02-08   ┆ 2021-02-08   ┆ 4051.01    ┆ 4748.07    ┆ member       │\n",
      "│ FE2F         ┆ e          ┆ 13:31:57     ┆ 13:50:45     ┆            ┆            ┆              │\n",
      "└──────────────┴────────────┴──────────────┴──────────────┴────────────┴────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "group1_pl_ridenorm=group1_pl.select(pl.col('*').exclude('start_station_name',\n",
    "                                         'end_station_name',\n",
    "                                         'start_lat',\n",
    "                                         'end_lat',\n",
    "                                         'start_lng',\n",
    "                                         'end_lng'))\n",
    "\n",
    "print(group1_pl_ridenorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e06e5-b8c4-4f9d-b628-13758cd07f4a",
   "metadata": {},
   "source": [
    "Station table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b563a416-ce3b-4e77-9190-82ddc901b396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (55_800_085, 8)\n",
      "┌────────────┬────────────┬────────────┬────────────┬───────────┬─────────┬───────────┬────────────┐\n",
      "│ start_stat ┆ start_stat ┆ end_statio ┆ end_statio ┆ start_lat ┆ start_l ┆ end_lat   ┆ end_lng    │\n",
      "│ ion_name   ┆ ion_id     ┆ n_name     ┆ n_id       ┆ ---       ┆ ng      ┆ ---       ┆ ---        │\n",
      "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆ f64       ┆ ---     ┆ f64       ┆ f64        │\n",
      "│ str        ┆ f64        ┆ str        ┆ f64        ┆           ┆ f64     ┆           ┆            │\n",
      "╞════════════╪════════════╪════════════╪════════════╪═══════════╪═════════╪═══════════╪════════════╡\n",
      "│ Broadway & ┆ 6173.08    ┆ E 2 St &   ┆ 5515.02    ┆ 40.742868 ┆ -73.989 ┆ 40.722174 ┆ -73.983688 │\n",
      "│ W 25 St    ┆            ┆ Avenue B   ┆            ┆           ┆ 186     ┆           ┆            │\n",
      "│ 46 Ave & 5 ┆ 6286.02    ┆ 34th Ave & ┆ 6873.01    ┆ 40.74731  ┆ -73.954 ┆ 40.765354 ┆ -73.939863 │\n",
      "│ St         ┆            ┆ Vernon     ┆            ┆           ┆ 51      ┆           ┆            │\n",
      "│            ┆            ┆ Blvd       ┆            ┆           ┆         ┆           ┆            │\n",
      "│ 46 Ave & 5 ┆ 6286.02    ┆ 34th Ave & ┆ 6873.01    ┆ 40.74731  ┆ -73.954 ┆ 40.765354 ┆ -73.939863 │\n",
      "│ St         ┆            ┆ Vernon     ┆            ┆           ┆ 51      ┆           ┆            │\n",
      "│            ┆            ┆ Blvd       ┆            ┆           ┆         ┆           ┆            │\n",
      "│ 46 Ave & 5 ┆ 6286.02    ┆ 34th Ave & ┆ 6873.01    ┆ 40.74731  ┆ -73.954 ┆ 40.765354 ┆ -73.939863 │\n",
      "│ St         ┆            ┆ Vernon     ┆            ┆           ┆ 51      ┆           ┆            │\n",
      "│            ┆            ┆ Blvd       ┆            ┆           ┆         ┆           ┆            │\n",
      "│ …          ┆ …          ┆ …          ┆ …          ┆ …         ┆ …       ┆ …         ┆ …          │\n",
      "│ E 47 St &  ┆ 6584.12    ┆ E 47 St &  ┆ 6584.12    ┆ 40.755102 ┆ -73.974 ┆ 40.755103 ┆ -73.974987 │\n",
      "│ Park Ave   ┆            ┆ Park Ave   ┆            ┆           ┆ 986     ┆           ┆            │\n",
      "│ Cedar St & ┆ 4721.01    ┆ Cedar St & ┆ 4721.01    ┆ 40.69671  ┆ -73.928 ┆ 40.69671  ┆ -73.92807  │\n",
      "│ Evergreen  ┆            ┆ Evergreen  ┆            ┆           ┆ 07      ┆           ┆            │\n",
      "│ Ave        ┆            ┆ Ave        ┆            ┆           ┆         ┆           ┆            │\n",
      "│ Bedford    ┆ 4066.15    ┆ Cedar St & ┆ 4721.01    ┆ 40.676368 ┆ -73.952 ┆ 40.69671  ┆ -73.92807  │\n",
      "│ Ave &      ┆            ┆ Evergreen  ┆            ┆           ┆ 918     ┆           ┆            │\n",
      "│ Bergen St  ┆            ┆ Ave        ┆            ┆           ┆         ┆           ┆            │\n",
      "│ Berkeley   ┆ 4051.01    ┆ Clinton St ┆ 4748.07    ┆ 40.675146 ┆ -73.975 ┆ 40.696233 ┆ -73.991421 │\n",
      "│ Pl & 7 Ave ┆            ┆ & Tillary  ┆            ┆           ┆ 232     ┆           ┆            │\n",
      "│            ┆            ┆ St         ┆            ┆           ┆         ┆           ┆            │\n",
      "└────────────┴────────────┴────────────┴────────────┴───────────┴─────────┴───────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "group1_pl_stationnorm=group1_pl.select(pl.col('*').exclude('ride_id',\n",
    "                                         'rideable_type',\n",
    "                                         'started_at',\n",
    "                                         'ended_at',\n",
    "                                         'member_casual'))\n",
    "\n",
    "print(group1_pl_stationnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e93214-5499-4af2-970c-94d7a9159047",
   "metadata": {},
   "source": [
    "## Convert the `polars` tables into a form that will make it easy to convert to `MySQL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdb5dab5-0b4a-42ea-9618-8d78f62ecd61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mysql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmysql\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmysql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnector\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a DataFrame (replace with your actual DataFrame)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mysql'"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Create a DataFrame (replace with your actual DataFrame)\n",
    "df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "                   'Age': [25, 30, 35],\n",
    "                   'City': ['New York', 'London', 'Paris']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ddc87d-96d5-4ad2-b4e1-bb30e3b53fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL connection details\n",
    "host = 'localhost'\n",
    "user = 'root'\n",
    "password = 'rootroot'\n",
    "database = 'citibike'\n",
    "table = 'rides'\n",
    "\n",
    "# Establish a connection to the MySQL server\n",
    "cnx = mysql.connector.connect(host=host, user=user, password=password, database=database)\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "# Create table query\n",
    "create_table_query = f\"CREATE TABLE {table} (Name VARCHAR(50), Age INT, City VARCHAR(50))\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Insert data into the table\n",
    "for _, row in df.iterrows():\n",
    "    insert_query = f\"INSERT INTO {table} (Name, Age, City) VALUES (%s, %s, %s)\"\n",
    "    values = (row['Name'], row['Age'], row['City'])\n",
    "    cursor.execute(insert_query, values)\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "cnx.commit()\n",
    "cursor.close()\n",
    "cnx.close()\n",
    "\n",
    "print(f\"Data has been inserted into table '{table}' in database '{database}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "255d9d23-fbe4-4316-831f-de91ad549e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/q8wb235x57n_sx2q14dsngjr0000gn/T/ipykernel_14509/3281893334.py:1: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  group1_pd=pd.read_csv(group1_location)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55800085 entries, 0 to 55800084\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ride_id             object \n",
      " 1   rideable_type       object \n",
      " 2   started_at          object \n",
      " 3   ended_at            object \n",
      " 4   start_station_name  object \n",
      " 5   start_station_id    object \n",
      " 6   end_station_name    object \n",
      " 7   end_station_id      object \n",
      " 8   start_lat           float64\n",
      " 9   start_lng           float64\n",
      " 10  end_lat             float64\n",
      " 11  end_lng             float64\n",
      " 12  member_casual       object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 5.4+ GB\n"
     ]
    }
   ],
   "source": [
    "group1_pd=pd.read_csv(group1_location)\n",
    "group1_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ffcba28b-d822-46a5-948b-ebde30a8765a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W 21 St & 6 Ave                 247908\n",
       "West St & Chambers St           219580\n",
       "1 Ave & E 68 St                 208483\n",
       "6 Ave & W 33 St                 197135\n",
       "Broadway & W 25 St              194687\n",
       "                                 ...  \n",
       "MTL-ECO51-1                          2\n",
       "Pier 40 Dock Station                 2\n",
       "Anthony Ave & E Burnside Ave         2\n",
       "Park Ave Depot                       1\n",
       "Pier 40 X2                           1\n",
       "Name: start_station_name, Length: 2037, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1_pd['start_station_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67545b79-539b-48b2-8a68-b3d11336662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "W 21 St & 6 Ave          248847\n",
       "West St & Chambers St    221084\n",
       "1 Ave & E 68 St          208961\n",
       "6 Ave & W 33 St          195770\n",
       "Broadway & W 25 St       195068\n",
       "                          ...  \n",
       "7 Ave & Bleecker St           1\n",
       "StuyTown Depot                1\n",
       "JCBS Depot                    1\n",
       "NYCBS DEPOT - PITT            1\n",
       "York St                       1\n",
       "Name: end_station_name, Length: 2050, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1_pd['end_station_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a0ef1-6732-498d-a614-9f4881b8a342",
   "metadata": {},
   "source": [
    "There seems to be some junk in the columns - I assumed it was clean when I downloaded it from Citibike, which I guess was a mistake. \n",
    "\n",
    "I'll need to clean the CSV before I convert the database to be SQL-ready in a future notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e905e8-46ba-4190-ad9e-5aebc8a3f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_pd.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ab7eb-5c52-4eaf-a217-cec23ddf1537",
   "metadata": {},
   "source": [
    "Displaying the value counts to disentangle the issue here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deff0fb9-e97f-4219-83ce-5a5d4ed4c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate value counts\n",
    "# counts = df['Column'].value_counts()\n",
    "\n",
    "# Filter based on value counts\n",
    "# filtered_df = df[df['Column'].isin(counts[counts >= 100].index)]\n",
    "\n",
    "# counts=group1_pd['start_station_name'].value_counts()\n",
    "\n",
    "# group1_pd[group1_pd['start_station_name'].isin(counts[counts >=100].index)].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576adb8-a08b-46f9-bf7c-83cb75761ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "148f8fa0-1e00-4f97-ba2c-db834ee550cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "Could not parse `Lab - NYC` as dtype `f64` at column 'start_station_id' (column number 6).\nThe current offset in the file is 2594650959 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `Lab - NYC` to the `null_values` list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# group1_pl=group1_pd.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m q\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m      4\u001b[0m     pl\u001b[38;5;241m.\u001b[39mscan_csv(group1_location)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# .filter(pl.col('member_casual')=='member')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# .sort(pl.col(''))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m df\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/polars/lazyframe/frame.py:1512\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, no_optimization, slice_pushdown, common_subplan_elimination, streaming)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     common_subplan_elimination \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m ldf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ldf\u001b[38;5;241m.\u001b[39moptimization_toggle(\n\u001b[1;32m   1504\u001b[0m     type_coercion,\n\u001b[1;32m   1505\u001b[0m     predicate_pushdown,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     streaming,\n\u001b[1;32m   1511\u001b[0m )\n\u001b[0;32m-> 1512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mComputeError\u001b[0m: Could not parse `Lab - NYC` as dtype `f64` at column 'start_station_id' (column number 6).\nThe current offset in the file is 2594650959 bytes.\n\nYou might want to try:\n- increasing `infer_schema_length` (e.g. `infer_schema_length=10000`),\n- specifying correct dtype with the `dtypes` argument\n- setting `ignore_errors` to `True`,\n- adding `Lab - NYC` to the `null_values` list."
     ]
    }
   ],
   "source": [
    "# group1_pl=group1_pd.\n",
    "\n",
    "q=(\n",
    "    pl.scan_csv(group1_location)\n",
    "    # .filter(pl.col('member_casual')=='member')\n",
    "    # .groupby('start_station_name')\n",
    "    # .with_columns([pl.col('count').count().alias('count')])\n",
    "    # .sort(pl.col(''))\n",
    ")\n",
    "\n",
    "df=q.collect()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e561c-9bcc-4c47-869f-1d7bef56ee9d",
   "metadata": {},
   "source": [
    "Use `parquvalue_counts store the large dataframes. They are currently in `.CSV` format and we will convert them to `parquet` format now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa2e9fdd-9b1e-41e9-8807-c6bec837bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/q8wb235x57n_sx2q14dsngjr0000gn/T/ipykernel_1313/275232640.py:1: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  group1=pd.read_csv(group1_location)\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "(\"Could not convert '6572.08' with type str: tried to convert to double\", 'Conversion failed for column start_station_id with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m group1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(group1_location)\n\u001b[0;32m----> 3\u001b[0m group1_pq\u001b[38;5;241m=\u001b[39m\u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m parquet_file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sra/files/projects/citibike_project/combined/group1_combined\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m pq\u001b[38;5;241m.\u001b[39mwrite_table(group1_pq, parquet_file_path)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/table.pxi:3557\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/concurrent/futures/thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/array.pxi:316\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: (\"Could not convert '6572.08' with type str: tried to convert to double\", 'Conversion failed for column start_station_id with type object')"
     ]
    }
   ],
   "source": [
    "group1=pd.read_csv(group1_location)\n",
    "\n",
    "group1_pq=pa.Table.from_pandas(group1)\n",
    "\n",
    "parquet_file_path='/Users/sra/files/projects/citibike_project/combined/group1_combined'\n",
    "pq.write_table(group1_pq, parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "45820957-65d2-4e79-987d-fce34212f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n3/q8wb235x57n_sx2q14dsngjr0000gn/T/ipykernel_1313/3645046789.py:3: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  group1=pd.read_csv(group1_location)\n"
     ]
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "(\"Could not convert '6572.08' with type str: tried to convert to double\", 'Conversion failed for column start_station_id with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert .CSV to .parquet\u001b[39;00m\n\u001b[1;32m      3\u001b[0m group1\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(group1_location)\n\u001b[0;32m----> 4\u001b[0m group1\u001b[38;5;241m=\u001b[39m\u001b[43mgroup1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup1_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m group1\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pandas/core/frame.py:2976\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2984\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2985\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pandas/io/parquet.py:430\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    428\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[0;32m--> 430\u001b[0m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pandas/io/parquet.py:174\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     from_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreserve_index\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m--> 174\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfrom_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    177\u001b[0m     path,\n\u001b[1;32m    178\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     is_dir\u001b[38;5;241m=\u001b[39mpartition_cols \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m )\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(path_or_handle, io\u001b[38;5;241m.\u001b[39mBufferedWriter)\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path_or_handle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle\u001b[38;5;241m.\u001b[39mname, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[1;32m    187\u001b[0m ):\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/table.pxi:3557\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/pandas_compat.py:624\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, maybe_fut \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_fut, futures\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m--> 624\u001b[0m             arrays[i] \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_fut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m types \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/concurrent/futures/thread.py:57\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_nullable \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mnull_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mField \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m was non-nullable but pandas column \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhad \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m null values\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[38;5;241m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[38;5;241m.\u001b[39mArrowTypeError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion failed for column \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[38;5;241m.\u001b[39mformat(col\u001b[38;5;241m.\u001b[39mname, col\u001b[38;5;241m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/array.pxi:316\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/bigdataml/lib/python3.8/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: (\"Could not convert '6572.08' with type str: tried to convert to double\", 'Conversion failed for column start_station_id with type object')"
     ]
    }
   ],
   "source": [
    "# convert .CSV to .parquet\n",
    "\n",
    "group1=pd.read_csv(group1_location)\n",
    "group1=group1.to_parquet(group1_location)\n",
    "group1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e759a58-947f-4e55-ab9a-dfeb22e7374c",
   "metadata": {},
   "source": [
    "Use the `polars` package to manipulate the large dataframes, `group1` and `group2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b9adc35-79a5-437e-9edd-e557e931e0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LazyGroupBy' object has no attribute 'collect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m q\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m      2\u001b[0m     pl\u001b[38;5;241m.\u001b[39mscan_csv(group1_location)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# .filter(pl.col('member_casual')=='member')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# .sort(pl.col(''))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LazyGroupBy' object has no attribute 'collect'"
     ]
    }
   ],
   "source": [
    "q=(\n",
    "    pl.scan_csv(group1_location)\n",
    "    # .filter(pl.col('member_casual')=='member')\n",
    "    .groupby('start_station_name')\n",
    "    # .with_columns([pl.col('count').count().alias('count')])\n",
    "    # .sort(pl.col(''))\n",
    ")\n",
    "\n",
    "df=q.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddd227c7-23e7-4673-a31d-b1a9eefadcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_038, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>start_station_name</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;W 21 St &amp; 6 Av…</td><td>247908</td></tr><tr><td>&quot;West St &amp; Cham…</td><td>219580</td></tr><tr><td>&quot;1 Ave &amp; E 68 S…</td><td>208483</td></tr><tr><td>&quot;6 Ave &amp; W 33 S…</td><td>197135</td></tr><tr><td>&quot;Broadway &amp; W 2…</td><td>194687</td></tr><tr><td>&quot;Broadway &amp; E 1…</td><td>190655</td></tr><tr><td>&quot;University Pl …</td><td>186543</td></tr><tr><td>&quot;Cleveland Pl &amp;…</td><td>181162</td></tr><tr><td>&quot;E 33 St &amp; 1 Av…</td><td>178145</td></tr><tr><td>&quot;E 17 St &amp; Broa…</td><td>176587</td></tr><tr><td>&quot;West St &amp; Libe…</td><td>175917</td></tr><tr><td>&quot;Broadway &amp; W 5…</td><td>171468</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Rogers Pl &amp; E …</td><td>11</td></tr><tr><td>&quot;Bleecker St &amp; …</td><td>9</td></tr><tr><td>&quot;W 40 St &amp; 8 Av…</td><td>8</td></tr><tr><td>&quot;E 6 St 2 Ave&quot;</td><td>7</td></tr><tr><td>&quot;Sharon St &amp; Ol…</td><td>4</td></tr><tr><td>&quot;S 5th St &amp; Ken…</td><td>4</td></tr><tr><td>&quot;Grand Concours…</td><td>2</td></tr><tr><td>&quot;MTL-ECO51-1&quot;</td><td>2</td></tr><tr><td>&quot;Anthony Ave &amp; …</td><td>2</td></tr><tr><td>&quot;Pier 40 Dock S…</td><td>2</td></tr><tr><td>&quot;Park Ave Depot…</td><td>1</td></tr><tr><td>&quot;Pier 40 X2&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_038, 2)\n",
       "┌──────────────────────────────┬────────┐\n",
       "│ start_station_name           ┆ count  │\n",
       "│ ---                          ┆ ---    │\n",
       "│ str                          ┆ u32    │\n",
       "╞══════════════════════════════╪════════╡\n",
       "│ W 21 St & 6 Ave              ┆ 247908 │\n",
       "│ West St & Chambers St        ┆ 219580 │\n",
       "│ 1 Ave & E 68 St              ┆ 208483 │\n",
       "│ 6 Ave & W 33 St              ┆ 197135 │\n",
       "│ …                            ┆ …      │\n",
       "│ Anthony Ave & E Burnside Ave ┆ 2      │\n",
       "│ Pier 40 Dock Station         ┆ 2      │\n",
       "│ Park Ave Depot               ┆ 1      │\n",
       "│ Pier 40 X2                   ┆ 1      │\n",
       "└──────────────────────────────┴────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb5398-2a4f-47d0-8b4a-18e65e47489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=(\n",
    "    pl.scan_csv('/Users/sra/files/projects/citibike_project/combined/group1_combined/group1.csv')\n",
    "    .groupby(by='start_station_name').count()\n",
    "    .sort(pl.col('count'),descending=True)\n",
    ")\n",
    "\n",
    "df=q.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203ab63-6909-48c4-b400-f0399cf005cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217943a9-eab9-411d-9bd5-96e213817fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
